{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: authors_filtered.csv\n",
      "Processed 0 valid authors, limited to 250.\n",
      "Cannot proceed with data insertion. Found 0 valid authors, but 250 are required.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import psycopg2\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "# Database connection parameters\n",
    "db_params = {\n",
    "    \"dbname\": \"authors_db\",\n",
    "    \"user\": \"book_user\",\n",
    "    \"password\": \"@book24**\",\n",
    "    \"host\": \"book_host\",\n",
    "    \"port\": \"5432\",\n",
    "}\n",
    "\n",
    "# change the db parameters of your own. this is are individual test parameter credentials.\n",
    "# Load the spaCy model for English language processing\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Constants\n",
    "CHUNK_SIZE = 50\n",
    "MAX_AUTHORS = 250\n",
    "MAX_TO_READ = 500\n",
    "MIN_AUTHORS_REQUIRED = 250\n",
    "\n",
    "def clean_title(title):\n",
    "    \"\"\"Cleans and validates book titles.\"\"\"\n",
    "    title = re.sub(r'^[‚Äú\"‚Äù‚Äò‚Äô]+|[‚Äú\"‚Äù‚Äò‚Äô]+$', \"\", title.strip())\n",
    "    meaningless_words = {\"phd\", \"ka\", \"the\", \"a\", \"an\", \"in\", \"on\", \"of\", \"for\", \"and\"}\n",
    "    words = title.split()\n",
    "    \n",
    "    if len(words) < 2 or len(words) > 5 or not set(word.lower() for word in words).intersection(meaningless_words):\n",
    "        return title.strip()\n",
    "    return None\n",
    "\n",
    "def is_english(title):\n",
    "    \"\"\"Checks if the title is in English.\"\"\"\n",
    "    return all(word.isalpha() or word.isspace() for word in title.split())\n",
    "\n",
    "def extract_book_titles(description):\n",
    "    \"\"\"Extracts book titles from the author's description using spaCy.\"\"\"\n",
    "    doc = nlp(description)\n",
    "    titles = [clean_title(ent.text) for ent in doc.ents if ent.label_ == \"WORK_OF_ART\"]\n",
    "    return [title for title in titles if title and is_english(title)]\n",
    "\n",
    "def construct_bio(about_text):\n",
    "    \"\"\"Returns the original bio text without modification.\"\"\"\n",
    "    return about_text\n",
    "\n",
    "\n",
    "def validate_author_data(author):\n",
    "    \"\"\"Validates the author's data.\"\"\"\n",
    "    return all([author[\"name\"], author[\"image_url\"], author[\"about\"]])\n",
    "\n",
    "def read_authors_from_csv(file_path):\n",
    "    \"\"\"Reads authors from a CSV file and returns a list of dictionaries.\"\"\"\n",
    "    authors_data = []\n",
    "    try:\n",
    "        with open(file_path, mode=\"r\", encoding=\"utf-8\") as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            for row in reader:\n",
    "                if len(authors_data) >= MAX_TO_READ:\n",
    "                    break\n",
    "\n",
    "                name = row.get(\"name\", \"\").strip()\n",
    "                image_url = row.get(\"image_url\", \"\").strip()\n",
    "                about = row.get(\"about\", \"\").strip()\n",
    "\n",
    "                if name and image_url and about:\n",
    "                    about_clean = re.sub(r\"<.*?>\", \"\", about)\n",
    "                    authors_data.append({\n",
    "                        \"name\": name,\n",
    "                        \"image_url\": image_url,\n",
    "                        \"about\": about_clean,  # Keep the cleaned bio intact\n",
    "                        \"books_written\": extract_book_titles(about_clean),\n",
    "                    })\n",
    "\n",
    "\n",
    "        print(f\"Read {len(authors_data)} authors from {file_path}.\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while reading CSV: {e}\")\n",
    "\n",
    "    return authors_data\n",
    "\n",
    "def insert_data_in_chunks(authors_data):\n",
    "    \"\"\"Inserts authors and their books into the database in chunks.\"\"\"\n",
    "    valid_authors_count = 0\n",
    "    try:\n",
    "        with psycopg2.connect(**db_params) as conn:\n",
    "            with conn.cursor() as cur:\n",
    "                for i in range(0, len(authors_data), CHUNK_SIZE):\n",
    "                    chunk = authors_data[i: i + CHUNK_SIZE]\n",
    "                    author_ids = {}\n",
    "\n",
    "                    for author in chunk:\n",
    "                        if not validate_author_data(author):\n",
    "                            print(f\"Invalid author data for: {author['name']}. Skipping.\")\n",
    "                            continue\n",
    "\n",
    "                        author_id = insert_author(cur, author)\n",
    "                        if author_id:\n",
    "                            author_ids[author[\"name\"]] = author_id\n",
    "                            valid_authors_count += 1\n",
    "\n",
    "                    insert_books(cur, chunk, author_ids)\n",
    "\n",
    "                    print(f\"Inserted {len(chunk)} authors and their books. Total valid authors so far: {valid_authors_count}\")\n",
    "\n",
    "                    if valid_authors_count >= MAX_AUTHORS:\n",
    "                        print(f\"Successfully validated {MAX_AUTHORS} authors.\")\n",
    "                        break\n",
    "\n",
    "                if valid_authors_count < MIN_AUTHORS_REQUIRED:\n",
    "                    print(f\"Cannot proceed with data insertion. Found {valid_authors_count} valid authors, but {MIN_AUTHORS_REQUIRED} are required.\")\n",
    "                else:\n",
    "                    print(f\"Successfully inserted {valid_authors_count} valid authors.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during data insertion: {e}\")\n",
    "\n",
    "def insert_author(cur, author):\n",
    "    \"\"\"Inserts a single author into the database.\"\"\"\n",
    "    try:\n",
    "        insert_author_query = \"\"\"\n",
    "            INSERT INTO library_author (name, image_url, bio)\n",
    "            VALUES (%s, %s, %s)\n",
    "            ON CONFLICT (name) DO NOTHING RETURNING id;\n",
    "        \"\"\"\n",
    "        cur.execute(insert_author_query, (author[\"name\"][:200], author[\"image_url\"][:200], author[\"about\"][:200]))\n",
    "        \n",
    "        if cur.rowcount > 0:\n",
    "            print(f\"Inserted author: {author['name']}\")\n",
    "            return cur.fetchone()[0]  # Return the new author ID\n",
    "        \n",
    "        print(f\"Author already exists: {author['name']}\")\n",
    "        return None  # If no row was inserted\n",
    "    except Exception as e:\n",
    "        print(f\"Error inserting author {author['name']}: {e}\")\n",
    "        return None\n",
    "\n",
    "def insert_books(cur, chunk, author_ids):\n",
    "    \"\"\"Inserts books associated with authors into the database.\"\"\"\n",
    "    insert_book_query = \"\"\"\n",
    "        INSERT INTO library_book (title, description, author_id, published_date)\n",
    "        VALUES (%s, %s, %s, %s)\n",
    "        ON CONFLICT (title, author_id) DO NOTHING;\n",
    "    \"\"\"\n",
    "    for author in chunk:\n",
    "        author_id = author_ids.get(author[\"name\"])\n",
    "        if author_id is None:\n",
    "            print(f\"Author ID not found for {author['name']}.\")\n",
    "            continue\n",
    "\n",
    "        for book in author.get(\"books_written\", []):\n",
    "            # Ensure the book is a string and not empty\n",
    "            if isinstance(book, str) and book.strip():\n",
    "                book_title = book.strip()  # Clean the book title\n",
    "                published_date = \"1900-01-01\"  # Default date if not provided\n",
    "\n",
    "                # Validate that the book title is not empty\n",
    "                if book_title:\n",
    "                    try:\n",
    "                        cur.execute(\n",
    "                            insert_book_query,\n",
    "                            (\n",
    "                                book_title,\n",
    "                                \"\",  # Assuming description can be empty or fetch from author data\n",
    "                                author_id,\n",
    "                                published_date,\n",
    "                            ),\n",
    "                        )\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error inserting book '{book_title}' for author '{author['name']}': {e}\")\n",
    "                else:\n",
    "                    print(f\"Invalid book title for author {author['name']}: {book}\")\n",
    "            else:\n",
    "                print(f\"Invalid book data for author {author['name']}: {book}\")\n",
    "\n",
    "def process_authors(file_path):\n",
    "    \"\"\"Processes authors from the CSV and inserts valid data into the database.\"\"\"\n",
    "    authors_data = read_authors_from_csv(file_path)\n",
    "\n",
    "    valid_authors = [author for author in authors_data if validate_author_data(author)][:MAX_AUTHORS]\n",
    "\n",
    "    print(f\"Processed {len(valid_authors)} valid authors, limited to {MAX_AUTHORS}.\")\n",
    "\n",
    "    if len(valid_authors) == MAX_AUTHORS:\n",
    "        insert_data_in_chunks(valid_authors)\n",
    "        print(f\"üéâ Successfully validated and added {MAX_AUTHORS} authors to the database!\")\n",
    "    else:\n",
    "        print(f\"Cannot proceed with data insertion. Found {len(valid_authors)} valid authors, but {MAX_AUTHORS} are required.\")\n",
    "\n",
    "# Execute the script\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file_path = \"authors_filtered.csv\"\n",
    "    process_authors(csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
